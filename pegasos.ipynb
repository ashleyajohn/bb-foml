{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provided Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from http://web.stanford.edu/class/cs221/ Assignment #2 Support Code\n",
    "def dotProduct(d1, d2):\n",
    "    \"\"\"\n",
    "    @param dict d1: a feature vector represented by a mapping from a feature (string) to a weight (float).\n",
    "    @param dict d2: same as d1\n",
    "    @return float: the dot product between d1 and d2\n",
    "    \"\"\"\n",
    "    if len(d1) < len(d2):\n",
    "        return dotProduct(d2, d1)\n",
    "    else:\n",
    "        return sum(d1.get(f, 0) * v for f, v in d2.items())\n",
    "\n",
    "def increment(d1, scale, d2):\n",
    "    \"\"\"\n",
    "    Implements d1 += scale * d2 for sparse vectors.\n",
    "    @param dict d1: the feature vector which is mutated.\n",
    "    @param float scale\n",
    "    @param dict d2: a feature vector.\n",
    "\n",
    "    NOTE: This function does not return anything, but rather\n",
    "    increments d1 in place. We do this because it is much faster to\n",
    "    change elements of d1 in place than to build a new dictionary and\n",
    "    return it.\n",
    "    \"\"\"\n",
    "    for f, v in d2.items():\n",
    "        d1[f] = d1.get(f, 0) + v * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import timeit\n",
    "\n",
    "'''\n",
    "Note:  This code is just a hint for people who are not familiar with text processing in python. There is no obligation to use this code, though you may if you like. \n",
    "'''\n",
    "\n",
    "\n",
    "def folder_list(path,label):\n",
    "    '''\n",
    "    Input: path to where the data is located and label (1 or -1 depending on positive or negative)\n",
    "    Output: list of file contents \n",
    "    '''\n",
    "    filelist = os.listdir(path)\n",
    "    review = []\n",
    "    for infile in filelist:\n",
    "        file = os.path.join(path,infile)\n",
    "        r = read_data(file)\n",
    "        r.append(label)\n",
    "        review.append(r)\n",
    "    return review\n",
    "\n",
    "def read_data(file):\n",
    "    '''\n",
    "    Read each file into a list of strings. \n",
    "    Example:\n",
    "    [\"it's\", 'a', 'curious', 'thing', \"i've\", 'found', 'that', 'when', 'willis', 'is', 'not', 'called', 'on', \n",
    "    ...'to', 'carry', 'the', 'whole', 'movie', \"he's\", 'much', 'better', 'and', 'so', 'is', 'the', 'movie']\n",
    "    '''\n",
    "    f = open(file)\n",
    "    lines = f.read().split(' ')\n",
    "    symbols = '${}()[].,:;+-*/&|<>=~\" '\n",
    "    words = map(lambda Element: Element.translate(None, symbols).strip(), lines)\n",
    "    words = filter(None, words)\n",
    "    return words\n",
    "\t\n",
    "###############################################\n",
    "######## YOUR CODE STARTS FROM HERE. ##########\n",
    "###############################################\n",
    "\n",
    "def shuffle_data():\n",
    "    '''\n",
    "    pos_path is where you save positive review data.\n",
    "    neg_path is where you save negative review data.\n",
    "    '''\n",
    "    pos_path = \"data/data/pos\"\n",
    "    neg_path = \"data/data/neg\"\n",
    "\t\n",
    "    pos_review = folder_list(pos_path,1)\n",
    "    neg_review = folder_list(neg_path,-1)\n",
    "\t\n",
    "    review = pos_review + neg_review\n",
    "    random.shuffle(review)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_path = \"data/data/pos\"\n",
    "neg_path = \"data/data/neg\"\n",
    "pos_review = folder_list(pos_path,1)\n",
    "neg_review = folder_list(neg_path,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle=shuffle_data()\n",
    "train = shuffle[:1500]\n",
    "test = shuffle[1500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make matrix of data + label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "def counter(data):\n",
    "    y = []\n",
    "    X = []\n",
    "    for i in range(len(data)):\n",
    "        y.append(data[i][-1])\n",
    "        X.append(collections.Counter(data[i][:-1]))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = counter(train)\n",
    "X_test, y_test = counter(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slow Pegasos Algo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos(X, y, lambda_reg, max_epochs):\n",
    "    t = 0\n",
    "    w = dict()\n",
    "    epoch = 0\n",
    "    while epoch < max_epochs:\n",
    "        epoch += 1\n",
    "        for i in range(len(X)):\n",
    "            t += 1\n",
    "            stepSize = 1/(t*lambda_reg)\n",
    "            if y[i]*dotProduct(w, X[i]) < 1: # if the entry multiplited by the dot prod of w,x[i], update gradient with product\n",
    "                increment(w,-stepSize*lambda_reg,w)\n",
    "                increment(w,stepSize*y[i],X[i])\n",
    "            else:#otherwise, update weight with existing times step size and lambda\n",
    "                increment(w,-stepSize*lambda_reg,w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Pegasos Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos_but_faster(X, y, lambd, max_epochs):\n",
    "    t = 1\n",
    "    w = dict()\n",
    "    s = 1\n",
    "    epoch = 0\n",
    "    while epoch < max_epochs:\n",
    "        epoch += 1\n",
    "        for i in range(len(X)):\n",
    "            t += 1\n",
    "            stepSize = 1/(t*lambd)\n",
    "            s *= (1-stepSize*lambd)\n",
    "            if s*y[i]*dotProduct(w, X[i]) < 1:\n",
    "                increment(w,(stepSize*y_train[i])/s,X_train[i])\n",
    "    increment(w,(s-1),w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(X, y, lambd, max_epochs): \n",
    "    print 'Slow Version'\n",
    "    startTime = timeit.default_timer()\n",
    "    w = pegasos(X_train, y_train, lambd, max_epochs)\n",
    "    endTime = timeit.default_timer()\n",
    "    print(\"Run Time (sec) = {0}\".format(endTime - startTime))\n",
    "    \n",
    "    print '\\nFast Version'\n",
    "    startTime = timeit.default_timer()\n",
    "    w = pegasos_but_faster(X_train, y_train, lambd, max_epochs)\n",
    "    endTime = timeit.default_timer()\n",
    "    print(\"Run Time (sec) = {0}\".format(endTime - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get error and best lambda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcError(w_list, X, y):\n",
    "    score_list = [accuracy(i, X, y) for i in w_list]\n",
    "    return score_list\n",
    "\n",
    "def accuracy(w, X, y):\n",
    "    count = 0\n",
    "    for i in range(len(X)):\n",
    "        if y[i]*dotProduct(w, X[i])<0:\n",
    "            count += 1\n",
    "    return count/(1. * len(X))\n",
    "\n",
    "def getbest(loss, lambdas, weights):\n",
    "    min_Loss = min(loss)\n",
    "    i = loss.index(min_Loss)\n",
    "    bestL = lambdas[i]\n",
    "    bestW = weights[i]\n",
    "    return bestL, bestW, min_Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the algo on an array of lambdas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_out_lambdas(X_train, y_train, lambda_reg_list, num_epochs):\n",
    "    classificationScore_list, w_list = [], []\n",
    "    startTime = timeit.default_timer()\n",
    "    for i in lambda_reg_list:\n",
    "        w = pegasos_but_faster(X_train, y_train, i, num_epochs)\n",
    "        w_list.append(w)\n",
    "        classificationScore_list.append(accuracy(w, X_train, y_train))\n",
    "    endTime = timeit.default_timer()\n",
    "    print(\"Run Time (sec) = {0}\".format(endTime - startTime))\n",
    "    return classificationScore_list, w_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find words that were incorrectly classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mistake_finder(X, y, w):\n",
    "    incorrect = []\n",
    "    for i in range(len(y)):\n",
    "        if y[i]*dotProduct(w, X[i])<0:\n",
    "            incorrect.append(X[i])\n",
    "    return incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run It All!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos_runner(lambd_arr): \n",
    "    print \"Prove that Fast is Fast\"\n",
    "    compare(X_train,y_train,0.1, 2)\n",
    "    \n",
    "    print \"\\nTraining\"\n",
    "    train_scores, w_list = try_out_lambdas(X_train,y_train,lambd_arr, 2)\n",
    "    score_list = calcError(w_list, X_train, y_train)\n",
    "    bestLambda, bestw, min_Loss = getbest(score_list, lambd_arr, w_list)\n",
    "    \n",
    "\n",
    "    print \"\\nTesting\"\n",
    "    mistakes = mistake_finder(X_test, y_test, bestw)\n",
    "    print(\"{0} misclassified words\".format(len(mistakes)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prove that Fast is Fast\n",
      "Slow Version\n",
      "Run Time (sec) = 111.520427135\n",
      "\n",
      "Fast Version\n",
      "Run Time (sec) = 0.464596112879\n",
      "\n",
      "Training\n",
      "Run Time (sec) = 1.97334542096\n",
      "\n",
      "Testing\n",
      "114 misclassified words\n"
     ]
    }
   ],
   "source": [
    "pegasos_runner([0.1, 0.15, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
